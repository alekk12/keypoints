{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cfdc788",
   "metadata": {},
   "source": [
    "The goal of the project is to simultaneously predict keypoints and age of the person in the image. This can be later combined with bounding box detection of a person or having multiple instances in the heatmaps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24556622",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5911603",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b485db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import torchvision.io as io\n",
    "import torch.nn.functional as F \n",
    "from PIL import Image\n",
    "import gc\n",
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597fe4e2",
   "metadata": {},
   "source": [
    "### Const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f42ede8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_KEYPOINTS = 17\n",
    "NUM_AGE_CLASSES = 2 #adult vs child, adult(1), child(0), no detection(-1), infant in the future (2), \n",
    "IMAGE_SIZE = (256, 192)\n",
    "HEATMAP_SIZE = (32,24)#(8,6)#(64, 48)\n",
    "B = 1\n",
    "C = 2 #how important is age to the loss\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "with open(\"./data/temp_config.json\") as json_conf:\n",
    "    CONF = json.load(json_conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78452e7",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0796b7",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f57632c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def gaussian(shape:tuple, center:tuple, sigma:int=2)->torch.Tensor:\n",
    "    \"\"\"Gaussian formula for smoothing/blurring\n",
    "    sigma is used because shape is circular\n",
    "    some versions use sigma_x, sigma_y for ellipsis\n",
    "\n",
    "    Args:\n",
    "        shape (tuple): heatmap size (h,w)\n",
    "        center (tuple): coordinates (x,y)\n",
    "        sigma (int, optional): parameter Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: heatmap\n",
    "    \"\"\"\n",
    "    h, w = shape\n",
    "    y = torch.arange(0,h).float()\n",
    "    x = torch.arange(0,w).float()\n",
    "    yy, xx = torch.meshgrid(y,x,indexing=\"ij\")\n",
    "    x0, y0 = center\n",
    "    return torch.exp(-((xx-x0)**2+(yy-y0)**2)/(2*sigma**2))\n",
    "\n",
    "def gaussian_2d(shape:tuple, center:tuple, sigma:int=1):\n",
    "        #xL, yL, H, W, sigma=5):\n",
    "    \"\"\"Function to create heatmaps by convoluting a 2D gaussian kernel over a (x,y) keypoint\n",
    "    from https://github.com/Fmak95/multi-stage-heatmap-regression/blob/master/facial-keypoint-detection.ipynb\n",
    "\n",
    "    Args:\n",
    "        xL (_type_): _description_\n",
    "        yL (_type_): _description_\n",
    "        H (_type_): _description_\n",
    "        W (_type_): _description_\n",
    "        sigma (int, optional): _description_. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    H, W = shape\n",
    "    xL, yL = center\n",
    "    #print(f\"c:{xL},{yL}|h:{H},W:{W}\")\n",
    "\n",
    "    channel = [math.exp(-((c - xL) ** 2 + (r - yL) ** 2) / (2 * sigma ** 2)) for r in range(H) for c in range(W)]\n",
    "    channel = np.array(channel, dtype=np.float32)\n",
    "    #print(channel)\n",
    "    channel = np.reshape(channel, newshape=(H, W))\n",
    "\n",
    "    return torch.Tensor(channel)\n",
    "\n",
    "def kps_to_heatmaps(kps:torch.Tensor, orig_img_size:tuple, nr_kps:int = NUM_KEYPOINTS, \n",
    "                    ht_size:tuple = HEATMAP_SIZE,\n",
    "                    img_size:tuple = IMAGE_SIZE,th:int=0)-> dict:\n",
    "    \"\"\"Converts keypoints of one person to a dictionary of heatmaps (one per keypoint)\n",
    "\n",
    "    Args:\n",
    "        kps (torch.Tensor): person's keypoints NUM_KEYPOINTS*3\n",
    "        nr_kps (int, optional): number of keypoints. Defaults to NUM_KEYPOINTS.\n",
    "        ht_size (int, optional): size of the heatmap. Defaults to HEATMAP_SIZE.\n",
    "        th (int, optional): threshold when keypoints are considered. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary of heatmaps, with one per keypoint (x,y)\n",
    "    \"\"\"\n",
    "    ht = torch.zeros(nr_kps, *ht_size)\n",
    "    ratio_x = ht_size[1] / orig_img_size[1]\n",
    "    ratio_y = ht_size[0] / orig_img_size[0]\n",
    "    for k in range(nr_kps):\n",
    "        x, y = kps[k*3:k*3+2]\n",
    "        x = x * ratio_y#ratio_x#ht_size[1]\n",
    "        y = y * ratio_x#ratio_y#ht_size[0]\n",
    "\n",
    "        ht[k] = gaussian_2d(\n",
    "            ht_size, center=(x,y),sigma=2\n",
    "        )\n",
    "    return ht\n",
    "\n",
    "def one_person_heatmaps_to_kps(hts:dict,img_size:tuple=IMAGE_SIZE, ht_size:tuple=HEATMAP_SIZE, th:int=0)->list:\n",
    "    \"\"\"Converts heatmaps of one person to keypoints\n",
    "       Each keypoint has (x,y,conf) where conf=2 means it is visible, conf=0 it was not detected\n",
    "\n",
    "    Args:\n",
    "        hts (dict): heatmaps\n",
    "        img_size (tuple, optional): size of the image. Defaults to IMAGE_SIZE.\n",
    "        ht_size (tuple, optional): _size/dimensions of the image. Defaults to HEATMAP_SIZE.\n",
    "        th (int, optional):threshold. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        list: list of keypoints\n",
    "    \"\"\"\n",
    "    k_nr, ht_h, ht_w = hts.shape\n",
    "    img_w, img_h = img_size\n",
    "    kps = []\n",
    "    for k in range(k_nr):\n",
    "        temp = hts[k]\n",
    "        if temp.max() <= th:\n",
    "            kps.extend([0,0,0])\n",
    "            continue\n",
    "        #resize\n",
    "        idx = temp.argmax()\n",
    "        x_img = (idx.item() % ht_w) * img_w/ht_w\n",
    "        y_img = (idx.item() // ht_w) * img_h/ht_h\n",
    "        kps.extend([x_img,y_img,2])\n",
    "    return kps\n",
    "\n",
    "def people_heatmaps_to_kps(ht)->list:\n",
    "    \"\"\"Converts heatmaps of multiple people to keypoints\n",
    "\n",
    "    Args:\n",
    "        ht (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        list: list of keypoints\n",
    "    \"\"\"\n",
    "    N, _, _, _ = ht.shape\n",
    "    all_keypoints = []\n",
    "    for n in range(N):\n",
    "        all_keypoints.extend(one_person_heatmaps_to_kps(ht[n]))\n",
    "    return all_keypoints\n",
    "\n",
    "def ht_to_coord(ht, topk:int=17)->torch.Tensor:\n",
    "    \"\"\"Converts heatmap to coordinates. Softmax is used to normalize the heatmaps\n",
    "\n",
    "    Args:\n",
    "        ht (_type_): heatmap\n",
    "        topk (int, optional): _description_. Defaults to 17.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: coordinates\n",
    "    \"\"\"\n",
    "    N, C, H, W = ht.shape\n",
    "    score, index = ht.view(N,C,1,-1).topk(topk, dim=-1)\n",
    "    coord = torch.cat([index%W, index//H], dim=2)\n",
    "    return (coord*F.softmax(score, dim=-1)).sum(-1)\n",
    "\n",
    "def load_data(ann, label_keys, th:int)->list:\n",
    "    \"\"\"Loads data as a list of dictionaries\n",
    "    Removes duplicates - only images where one person is detected are used\n",
    "    Only images with age label are used.\n",
    "\n",
    "    Args:\n",
    "        ann (dict): annotations\n",
    "        label_keys (dict_keys): age label\n",
    "        th (int):min number of keypoints\n",
    "\n",
    "    Returns:\n",
    "        list: data with annotations\n",
    "    \"\"\"\n",
    "    data = [a for a in ann if a['num_keypoints'] > th and a['image_id'] in label_keys]\n",
    "    counts = Counter(d['image_id'] for d in data)\n",
    "    data = [d for d in data if counts[d['image_id']]==1]\n",
    "    print(f\"Annotations:{len(data)}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75aa0a4",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "12bd3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputDataset(Dataset):\n",
    "    def __init__(self, ann_path:str, data_dir:str, label_path:str,th:int=0,is_gag:bool=False):\n",
    "        self.data_dir = data_dir\n",
    "        with open(ann_path, \"r\" ) as f:\n",
    "            ann = json.load(f)\n",
    "        self.labels = pd.read_csv(label_path).set_index('image_id').T.to_dict()\n",
    "        self.data = load_data(ann['annotations'], self.labels.keys(), th)\n",
    "        self.id_to_name_map = {\n",
    "            img['id'] : img['file_name']\n",
    "            for img in ann['images']\n",
    "        }\n",
    "        self.is_gag = is_gag\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize(IMAGE_SIZE),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485,0.456,0.406],\n",
    "                        std=[0.229,0.224,0.225])\n",
    "        ])\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        kp = self.data[index]\n",
    "        img_id = kp['image_id']\n",
    "        img_path = os.path.join(\n",
    "            self.data_dir,\n",
    "            self.id_to_name_map[img_id]\n",
    "        )\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        kps = torch.tensor(kp['keypoints']).float()\n",
    "        ht = kps_to_heatmaps(kps,image.size)\n",
    "        image = self.transform(image)\n",
    "        age = torch.tensor(int(self.labels[img_id]['age']=='adult'), dtype=torch.int64)        \n",
    "        return image, ht, age\n",
    "    \n",
    "\n",
    "class MixedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-2])#removes classification\n",
    "        self.pose_head = nn.Sequential(\n",
    "            nn.Conv2d(2048,256,3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,NUM_KEYPOINTS,1)\n",
    "        )\n",
    "        self.age_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048,256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, NUM_AGE_CLASSES)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        ht = self.pose_head(feat)\n",
    "        age = self.age_head(feat)\n",
    "        return ht, age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8963cf83",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce0383",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ee7566bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(model:MixedModel, epochs:int, loader:DataLoader, optimizer, scheduler, \n",
    "                 pose_criterion, age_criterion, device:str=DEVICE,\n",
    "                 path:str=CONF['default_model_path'], save_model=True,\n",
    "                 step_print:bool=True, \n",
    "                 th:int=0.25, B:int=1,C:int=2):\n",
    "    \"\"\"Train the model for `epochs`. Save model in the given `path`\n",
    "\n",
    "    Args:\n",
    "        model (MixedModel): _description_\n",
    "        epochs (int): _description_\n",
    "        loader (DataLoader): _description_\n",
    "        optimizer (_type_): _description_\n",
    "        scheduler (_type_): _description_\n",
    "        pose_criterion (_type_): _description_\n",
    "        age_criterion (_type_): _description_\n",
    "        device (str, optional): _description_. Defaults to DEVICE.\n",
    "        path (str, optional): _description_. Defaults to './model_heatmap.pth'.\n",
    "    \"\"\"\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        for images, gt_heatmaps, age_labels in loader:\n",
    "            optimizer.zero_grad()\n",
    "            images = images.to(device)\n",
    "            gt_heatmaps = gt_heatmaps.to(device)\n",
    "            pred_heatmaps, pred_age = model(images)\n",
    "            loss_pose = pose_criterion(pred_heatmaps, gt_heatmaps)\n",
    "            loss = loss_pose\n",
    "            age_labels = age_labels.to(device)\n",
    "            loss_age = age_criterion(pred_age, age_labels)\n",
    "            loss = B * loss + C * loss_age            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        scheduler.step()\n",
    "        epoch_loss = round(total_loss / num_batches,4)\n",
    "        lr = round(scheduler.get_last_lr()[0],4)\n",
    "        print(f\"Epoch {e}: loss = {epoch_loss:.4f} lr = {lr}\")\n",
    "        if save_model and step_print and epoch_loss < th:\n",
    "            torch.save(model.state_dict(),f'{CONF[\"model_dir\"]}/model_train_heatmap_{epoch_loss}loss_{e}_{epochs}ep_{lr}lr_Adam_OneCycleLR.pth')\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), path)  \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9516a",
   "metadata": {},
   "source": [
    "* MSELoss ranges from $0$ to $1$\n",
    "* CrossEntropyLoss (for two classes, `adult` and `child`) ranges from $0$ to $0.693$ \n",
    "  \n",
    "The final loss formula is `B * pose_loss + C * age_loss` where $C$ is a constant\n",
    "\n",
    "I decided to make $B$ equal to $1$ and $C$ equal to $2$ since age is really imporant in this model\n",
    "\n",
    "The final loss ranges from $0$ to $2.386$ with good values of loss being less than $0.24$ (scaled to 0-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6bd089fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_criterion = nn.MSELoss(reduction='mean') #normalize heatmap, good especially for large heatmaps\n",
    "age_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d02b5b",
   "metadata": {},
   "source": [
    "* `keypoints_path` - json from coco website with information. It has `annotations` where each annotation has the `keypoints`, `num_keypoints`, `image_id`, `id` and `images` with `filename` and other information about the images.\n",
    "* `img_dir` - directory with jpg images from `keypoints_path` json\n",
    "* `label_path` - path to a csv. The ages were predicted using both the body ratios (MMU gag dataset) and captions from coco dataset, then manually verified by looking through images. Csv has three columns `age` (child|adult), `image_id` (filename), `id`\n",
    "* `lr` - learning rate chosen using optuna after adding the scheduler\n",
    "* `epochs` - number of epochs chosen using optuna + verified by saving each model after certain number of epochs\n",
    "* `opt` - Adam optimizer used for training\n",
    "* `sch` - OneCycleLR used as a scheduler, the learning rate is annealed until we reach maximum and then we decrease the learning rate lower than the initial learning rate `lr`\n",
    "* `heatmap` - this version of the model uses heatmaps while predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ae3213dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations:3096\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "epochs = 10\n",
    "opt = \"Adam\"\n",
    "sch = \"OneCycleLR\"\n",
    "ht = \"heatmap\"\n",
    "\n",
    "path = f'{CONF[\"model_dir\"]}model_train_{ht}_lr{lr}_ep{epochs}_opt{opt}_sch{sch}.pth'\n",
    "\n",
    "train_data = InputDataset(CONF['train_keypoints_path'],CONF['train_img_dir'], CONF['train_label_path'])\n",
    "train_loader = DataLoader(train_data, batch_size=64, num_workers=0,pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b280b9a",
   "metadata": {},
   "source": [
    "### Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527012b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() #clears cache bcs sometimes it breaks\n",
    "    \n",
    "    model = MixedModel().to(DEVICE)\n",
    "\n",
    "    #for param in model.backbone.parameters():\n",
    "    #    param.requires_grad = False\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                max_lr = lr,\n",
    "                                                steps_per_epoch=len(train_loader),\n",
    "                                                epochs=epochs,\n",
    "                                                pct_start=0.1,\n",
    "                                                anneal_strategy='cos'\n",
    "                                                )\n",
    "\n",
    "    #for p in model.age_head.parameters():\n",
    "    #    p.requires_grad = False\n",
    "\n",
    "    # TO DO\n",
    "    # add backbone freezing, then training, then unfreeze\n",
    "\n",
    "    epoch_loss = train_epochs(model, epochs, train_loader, optimizer,\n",
    "                              scheduler, pose_criterion, age_criterion, path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c9f1d",
   "metadata": {},
   "source": [
    "### Optuna study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb86383b",
   "metadata": {},
   "source": [
    "#### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def objective(trial)->float:\n",
    "    \"\"\"Runs each trial\n",
    "\n",
    "    Args:\n",
    "        trial (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        float: Returns loss when training\n",
    "    \"\"\"\n",
    "    model = MixedModel().to(DEVICE)\n",
    "    pose_criterion = nn.MSELoss(reduction='mean') #normalize heatmap, good especially for large heatmaps\n",
    "    age_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    #for p in model.age_head.parameters():\n",
    "    #    p.requires_grad = False\n",
    "    # TO DO\n",
    "    # add backbone freezing, then training, then unfreeze\n",
    "        \n",
    "    epochs = trial.suggest_int(\"epochs\",0,100)\n",
    "    lr = trial.suggest_int(\"lr\",1e-3, 1e-1)\n",
    "    pct_start = trial.suggest_float(\"pct_start\",0.05, 0.3)\n",
    "    batch_size = trial.suggest_int(\"batch_size\",2, 256)\n",
    "    train_data = InputDataset(CONF['train_keypoints_path'],CONF['train_img_dir'], CONF['train_label_path'])\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=0, pin_memory=True, shuffle=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                max_lr = lr,\n",
    "                                                steps_per_epoch=len(train_loader),\n",
    "                                                epochs=epochs,\n",
    "                                                pct_start=pct_start,\n",
    "                                                anneal_strategy='cos'\n",
    "                                                )\n",
    "    return train_epochs(model, epochs, train_loader, optimizer, scheduler, pose_criterion, age_criterion, save_model=False, step_print=False)\n",
    "    # model.fit(X_train, y_train)\n",
    "    # y_pred = model.predict(X_test)\n",
    "    # return accuracy_score(y_test, y_pred)\n",
    "    #TO DO\n",
    "    # add accuracy of age and separately for heatmaps/keypoints\n",
    "\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "sampler = TPESampler(seed=1)\n",
    "\n",
    "study = optuna.create_study(study_name=\"coco\", direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5819c05b",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47beef5c",
   "metadata": {},
   "source": [
    "Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "dccaa606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(model:MixedModel, loader:DataLoader,\n",
    "                 pose_criterion, age_criterion, device:str=DEVICE,\n",
    "                 B:int=1, C:int=2)->tuple[list,list,list, list]:\n",
    "    \"\"\" Predict for all data in the test loader\n",
    "\n",
    "    Args:\n",
    "        model (MixedModel): _description_\n",
    "        epochs (int): _description_\n",
    "        loader (DataLoader): _description_\n",
    "        pose_criterion (_type_): _description_\n",
    "        age_criterion (_type_): _description_\n",
    "        device (str, optional): _description_. Defaults to DEVICE.\n",
    "        path (str, optional): _description_. Defaults to './model_heatmap.pth'.   \n",
    "    Returns:\n",
    "        tuple[list,list]: returns two lists of keypoints, one extracted normally and one softmaxed, \n",
    "        one list with age, one list with heatmaps\n",
    "    \"\"\"\n",
    "    kps = []\n",
    "    kps2 = []\n",
    "    age = []\n",
    "    ht = []\n",
    "    total_loss = 0.0\n",
    "    total_age_loss = 0.0\n",
    "    total_kp_loss = 0.0\n",
    "    num_batches = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, gt_heatmaps, age_labels in loader:\n",
    "                images = images.to(device)\n",
    "                gt_heatmaps = gt_heatmaps.to(device)\n",
    "                pred_heatmaps, pred_age = model(images)\n",
    "                #plt.figure(figsize=(4,3))\n",
    "                #sns.heatmap(gt_heatmaps[0][0].cpu(), cmap=\"crest\")\n",
    "                #plt.show()\n",
    "                #plt.close()\n",
    "                # print(age_labels)\n",
    "                #print(torch.sigmoid(pred_age))\n",
    "                # print(pred_age.max(dim=1)[0].to(dtype=torch.int64))\n",
    "                # print(pred_age.argmax().to(dtype=torch.int64))\n",
    "                # print(pred_age.to(dtype=torch.int64).argmax())\n",
    "                # print(pred_age.to(dtype=torch.int64).argmax().flatten())\n",
    "                #pred_age = pred_age.max(dim=1)[0].to(dtype=torch.int64)\n",
    "                #pred_age = pred_age.to(dtype=torch.int64).argmax()\n",
    "                ht.extend(pred_heatmaps)\n",
    "                kps.extend(people_heatmaps_to_kps(pred_heatmaps))\n",
    "                kps2.extend(ht_to_coord(pred_heatmaps))\n",
    "                loss_pose = pose_criterion(pred_heatmaps, gt_heatmaps)\n",
    "                total_kp_loss += loss_pose.item()\n",
    "                loss = loss_pose\n",
    "                age_labels = age_labels.to(DEVICE)\n",
    "                loss_age = age_criterion(pred_age, age_labels)\n",
    "                total_age_loss += loss_age.item()\n",
    "                age.extend(torch.argmax(pred_age, dim=1))\n",
    "                loss = B * loss + C * loss_age\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "        print(f\"Testing loss = {total_loss / num_batches:.4f}. Age = {total_age_loss/num_batches:.4f} Kp = {total_kp_loss/num_batches:.4f}\")\n",
    "    return kps, kps2, age, ht"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65149cc8",
   "metadata": {},
   "source": [
    "Load Test/Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7d04a8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations:1232\n"
     ]
    }
   ],
   "source": [
    "val_data = InputDataset(CONF['val_keypoints_path'],CONF['val_img_dir'], CONF['val_label_path'])\n",
    "val_loader = DataLoader(val_data, batch_size=64, num_workers=0, pin_memory=True, shuffle=True)\n",
    "pose_criterion = nn.MSELoss(reduction='mean') #normalize heatmap, good especially for large heatmaps\n",
    "age_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ecd85dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing loss = 1.4174. Age = 0.7075 Kp = 0.0024\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() #clears cache bcs sometimes it breaks\n",
    "    model_path = CONF['best_model']\n",
    "    \n",
    "    model = MixedModel().to(DEVICE)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE, weights_only=True))\n",
    "    \n",
    "    kps, soft_kps, age, ht = run_test(model, val_loader, pose_criterion, age_criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d0b60d",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0fbe55b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286813"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.data[0]['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a95f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = []\n",
    "for i in range(len(val_data)):\n",
    "    it = val_data.__getitem__(i)[2]\n",
    "    ages.append(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481de521",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "n = len(val_data)\n",
    "for i in range(n):\n",
    "    c += int(ages[i]==age[i])\n",
    "print(round(c/n,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a93dd623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.__getitem__(0)[2] == age[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5b42bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([348, 212,   2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(val_data.data[0]['keypoints'], (-1,3))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(val_data.__getitem__(0)[1][2].cpu(), cmap=\"crest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c569e0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(ht[0][3].cpu(), cmap=\"crest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d0360e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([298, 161,   2])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(val_data.data[1]['keypoints'], (-1,3))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bd74263a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2406,  0.1406,  0.1134,  0.0378,  0.0174,  0.0012, -0.0012, -0.0024, -0.0009, -0.0010,  0.0011,  0.0045,  0.0065,  0.0066,  0.0072,  0.0070,  0.0094,  0.0074,  0.0047,  0.0023,  0.0033, -0.0003, -0.0016,  0.0014])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht[0][1][0].cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe2777",
   "metadata": {},
   "source": [
    "## Run on real videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5558d56",
   "metadata": {},
   "source": [
    "The plan is to track people and get the boxes and detect keypoints+age on the cropped images. The issue is occlusion and people leaving and reappearing in the view.\n",
    "\n",
    "TO DO: combine permanent id tracking, saving the ids for some time and reid (current version has iding based on ratios which is not memory efficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8383e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_boxes(vid_path:str, box_path:str, track_path:str, out_dir:str, device:str=DEVICE)->list:\n",
    "    \"\"\"Detect and save boxes\"\"\"\n",
    "    box_model = YOLO(box_path)\n",
    "    box_model.to(device)\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(vid_path)\n",
    "    except:\n",
    "        print(\"No video\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(out_dir,exist_ok=True)\n",
    "\n",
    "    frame_nr = 0\n",
    "    boxes = []\n",
    "\n",
    "    results = box_model.track(\n",
    "            source=vid_path,\n",
    "            classes=[0],\n",
    "            persist=True,\n",
    "            verbose=False,\n",
    "            show=False, \n",
    "            tracker=track_path,\n",
    "            stream=True\n",
    "        )\n",
    "    for r in results:\n",
    "        frame_nr += 1\n",
    "        if len(r.boxes)==0:\n",
    "            continue\n",
    "        frame = r.orig_img\n",
    "        width, height, _ = frame.shape\n",
    "        boxes_xyxy = r.boxes.xyxy.cpu().numpy().astype(int)\n",
    "        tracker_ids = (r.boxes.id.int().cpu().numpy().astype(int)\n",
    "                       if r.boxes.id is not None\n",
    "                       else [-1] * len(boxes)\n",
    "                       )\n",
    "        for b, t in zip(boxes_xyxy, tracker_ids):\n",
    "            x1,y1,x2,y2 = map(int,b)\n",
    "            x1, y1,x2,y2 = max(0,x1),max(0,y1),min(width,x2),min(height,y2)\n",
    "            boxes.append({\n",
    "                'frame_nr':frame_nr,\n",
    "                'id': t,\n",
    "                'bbox':(x1,y1,x2,y2)\n",
    "            })\n",
    "            cv2.imwrite(f\"{out_dir}frame_{frame_nr}_id_{t}.jpg\",frame[y1:y2,x1:x2])\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c60a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = save_boxes(CONF['video_path'],CONF[\"box_model\"],CONF[\"tracking\"],CONF['crops_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a8e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "keypoint_names = [\n",
    "\"nose\",\"left_eye\", \"right_eye\", \"left_ear\", \"right_ear\", \"left_shoulder\", \"right_shoulder\",\"left_elbow\", \"right_elbow\",\n",
    "\"left_wrist\", \"right_wrist\", \"left_hip\", \"right_hip\", \"left_knee\", \"right_knee\",\"left_ankle\", \"right_ankle\"\n",
    "]\n",
    "\n",
    "\n",
    "def calc_skeleton(kps, conf, frame_number, person_id)->list:\n",
    "    \"\"\"Calculate skeleton\"\"\"\n",
    "    kp = np.array(kps)\n",
    "    c = np.array(conf)\n",
    "    row = [frame_number,person_id]\n",
    "    for i, (x, y) in enumerate(kp):\n",
    "        row.extend([float(x), float(y),float(c[i])])\n",
    "    return row "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b30fae0",
   "metadata": {},
   "source": [
    "### Run prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684909d",
   "metadata": {},
   "source": [
    "### Display keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9161b657",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2982795",
   "metadata": {},
   "source": [
    "1. [Tutorial on adding another head when predicting](https://y-t-g.github.io/tutorials/yolov8n-add-classes/)\n",
    "2. [Ultralytics model training](https://docs.ultralytics.com/modes/train/#idle-gpu-training)\n",
    "3. [Roboflow tutorial](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/train-yolov8-keypoint.ipynb)\n",
    "4. [Keypoints with heatmaps](https://www.slingacademy.com/article/creating-a-keypoint-detection-model-with-pytorch-and-heatmap-regression/)\n",
    "5. [Tutorial on keypoints regression, used some heatmap functions](https://elte.me/2021-03-10-keypoint-regression-fastai)\n",
    "6. [Heatmap transform](https://github.com/baoshengyu/H3R/blob/master/torchalign/heatmap_head/transforms/functional.py)\n",
    "7. [Heatmap regression via randomized rounding](https://github.com/baoshengyu/H3R)\n",
    "8. [More heatmaps](https://github.com/Fmak95/multi-stage-heatmap-regression/blob/master/facial-keypoint-detection.ipynb)\n",
    "9. [Frozen layers](https://medium.com/we-talk-data/guide-to-freezing-layers-in-pytorch-best-practices-and-practical-examples-8e644e7a9598)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
